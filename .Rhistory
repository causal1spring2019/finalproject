X1=X
X1$bullied = 1
#run SL
SL.treated = SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=5))
SL.control = SuperLearner(Y=Y, X=X0, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predctions = matrix(NA, nrow=nrow(final_data), ncol=2)
predictions$one = SL.treated$SL.predict
# get predicted outcomes under both scenarios
predctions = matrix(NA, nrow=nrow(final_data), ncol=2)
predictions$one = SL.treated$SL.predict
# get predicted outcomes under both scenarios
predictions = matrix(NA, nrow=nrow(final_data), ncol=2)
predictions$one = SL.treated$SL.predict
View(predictions)
predict.1 = SL.treated$SL.predict
predict.0 = SL.control$SL.predict
#g-comp
mean(predict.1-predict.0)
mean(predict.1/predict.0)
library(plyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(childsds)
library(epiR)
library(SuperLearner)
library(ltmle)
knitr::opts_chunk$set(include = FALSE, cache = TRUE)
# First, load the data
ShelleyStephLizzyVeronicaDataLoad <- function(filename)
{
if(Sys.info()['sysname']=="Darwin"){
macfilepath <- paste("./NLSY Data/", filename, sep = "")
load(as.character(macfilepath), envir = globalenv())}
else{
windowsfilepath <- paste("~/GitHub/finalproject/NLSY Data/", filename, sep = "")
load(as.character(windowsfilepath), envir = globalenv())
}
}
ShelleyStephLizzyVeronicaDataLoad("imputed_data.Rdata")
final_data <- imputed_data
rm(imputed_data)
load("final_data_BMIz.RData")
# #G-comp with SuperLearner
# Create SL library
SL.library = c("SL.glmnet", "SL.glm","SL.glm.interaction", "SL.randomForest")
load("final_data_BMIz.RData")
table(final_data)
names(final_data)
# set treatment at 0 and 1
X0 = X
# create dataset of Ws
X<- subset(final_data, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997"))
# set treatment at 0 and 1
X0 = X
X0$bullied = 0
X1=X
X1$bullied = 1
# create a vector of Y
Y = as.numeric(final_data$ever_new_user2)
table(Y)
Y = ifelse(Y==1, 0, 1)
table(Y)
#run SL on treatment and control
SL.treated = SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=5))
SL.control = SuperLearner(Y=Y, X=X0, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1 = SL.treated$SL.predict
predict.0 = SL.control$SL.predict
#g-comp for ATE
mean(predict.1-predict.0)
#run SL on treatment and control
SL.treated = SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=5))
SL.control = SuperLearner(Y=Y, X=X0, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1 = SL.treated$SL.predict
predict.0 = SL.control$SL.predict
#g-comp for ATE
mean(predict.1-predict.0)
#run SL on treatment and control
SL.treated = CV.SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=5))
#run SL on treatment and control
SL.treated = CV.SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=4))
#run SL on treatment and control
SL.treated = CV.SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=3))
#run SL on treatment and control
SL.treated = SuperLearner(Y=Y, X=X1, SL.library=SL.library, family='binomial', cvControl=list(V=5))
SL.control = SuperLearner(Y=Y, X=X0, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1 = SL.treated$SL.predict
predict.0 = SL.control$SL.predict
#g-comp for ATE
mean(predict.1-predict.0)
## Stabilized IPTW with SuperLearner
# estimate treatment mechanism
A=as.numeric(final_data$bullied_bf_12_1997)
table(final_data$bullied_bf_12_1997)
table(A)
A=ifelse(A==1,0,1)
table(A)
gAW<- SuperLearner(Y=A, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# estimate treatment mechanism
gAW.sl<- SuperLearner(Y=A, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
gAW = ifelse(final_data$bullied_bf_12_1997==1, SL.treated$SL.predict, 1-SL.treated$SL.predict)
summary(gAW)
summary(SL.treated$SL.predict)
predict(gAW.sl, type= "response")
# predicted prob of observed treatment
gAW = ifelse(final_data$bullied_bf_12_1997==1, SL.treated$SL.predict, ifelse(final_data$bullied_bf_12_1997==0, 1-(SL.treated$SL.predict), NA))
summary(gAW)
# predicted prob of observed treatment
pred.g1W = SL.treated$SL.predict
pred.g0W = 1- SL.treated$SL.predict
gAW = ifelse(final_data$bullied_bf_12_1997==1, pred.g1W, pred.g0W)
table(gAW)
summary(gAW)
summary(pred.g0W)
gAW = ifelse(A==1, pred.g1W, pred.g0W)
summary(gAW)
# weights = 1/prob treatment
wt = 1/gAW
summary(wt)
table(final_data$bullied_bf_12_1997)
table(final_data$ever_new_user2)
class(final_data$ever_new_user2)
mean( wt*as.numeric(final_data$bullied_bf_12_1997=="NotBullied")*final_data$ever_new_user2)/mean( wt*as.numeric(final_data$bullied_bf_12_1997=="NotBullied"))
# 7. Stabilized IPTW estimator
AY = c(A,Y)
# 7. Stabilized IPTW estimator
AY = cbind(A,Y)
View(AY)
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
# 7. Stabilized IPTW estimator
AY = as.data.frame(cbind(A,Y))
mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1) -
mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
)
mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
set.seed(4864)
## TMLE
X$bullied = final_data$bullied_bf_12_1997
View(X)
table(Y)
table(A)
#predict y give Ws
QbarSL<- SuperLearner(Y=Y, X=X, SL.library=SL.library, family="binomial")
#predict y give Ws
QbarSL<- SuperLearner(Y=Y, X=X, SL.library=SL.library, family="binomial", cvControl=list(V=5))
QbarSL
# get the predicted outcomes
QbarAW = predict(QbarSL, newdata=final_data)$pred
# get the predicted outcomes
QbarAW = predict(QbarSL, newdata=X)$pred
# expected injury severity, given A=1 and covariates
Qbar1W = predict(QbarSL, newdata=X1)$pred
names(X1)
## TMLE
X$bullied = A
#predict y give Ws
QbarSL = SuperLearner(Y=Y, X=X, SL.library=SL.library, family="binomial", cvControl=list(V=5))
# get the predicted outcomes
QbarAW = predict(QbarSL, newdata=X)$pred
# expected injury severity, given A=1 and covariates
Qbar1W = predict(QbarSL, newdata=X1)$pred
# expected injury severity, given A=0 and covariates
Qbar0W = predict(QbarSL, newdata=X0)$pred
tail(data.frame(A=X$A, QbarAW, Qbar1W, Qbar0W))
tail(data.frame(X$A, QbarAW, Qbar1W, Qbar0W))
tail(data.frame(A, QbarAW, Qbar1W, Qbar0W))
mean(Qbar1W - Qbar0W)
load("final_data_BMIz.RData")
set.seed(4864)
##G-comp with SuperLearner
# Create SL library
SL.library = c("SL.glmnet", "SL.glm","SL.glm.interaction", "SL.randomForest")
# create dataset of Ws
X<- subset(final_data, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997"))
X$bullied=as.numeric(final_data$bullied_bf_12_1997)
X$bullied=ifelse(X$bullied==1,0,1)
table(X$bullied)
# set treatment at 0 and 1
X0 = X
X0$bullied = 0
table(X0$bullied)
X1=X
X1$bullied = 1
# create a vector of Y
Y = as.numeric(final_data$ever_new_user2)
Y = ifelse(Y==1, 0, 1)
#run SL
SL.pred = SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
pred1=predict(SL.pred, newdata=X1)$pred
predict.0 = predict(SL.pred, newdata=X0)$pred
#g-comp for ATE
gComp = mean(predict.1-predict.0)
# get predicted outcomes under both scenarios
predict.1 = predict(SL.pred, newdata=X1)$pred
#g-comp for ATE
gComp = mean(predict.1-predict.0)
## Stabilized IPTW with SuperLearner
# make A a vector
A=as.numeric(final_data$bullied_bf_12_1997)
A=ifelse(A==1,0,1)
# just Ws
W = subset(X, select=-"bullied")
names(X)
# just Ws
W = subset(X, select=c(1:5))
# estimate treatment mechanism
gAW.sl = SuperLearner(Y=A, X=W, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W = predict(gAW.sl, newdata=X)$pred
# predicted prob of observed treatment
pred.g1W = predict(gAW.sl, newdata=W)$pred
# predicted prob of observed treatment
pred.g1W = predict(gAW.sl, type= "response")
pred.g0W = 1- pred.g1W
View(pred.g1W)
pred.g1W[["library.predict"]]
# predicted prob of observed treatment
pred.g1W = predict(gAW.sl, type= "response")$pred
head(pred.g1W)
pred.g0W = 1- pred.g1W
gAW = ifelse(A==1, pred.g1W, pred.g0W)
# weights = 1/prob treatment
wt = 1/gAW
# Stabilized IPTW estimator
AY = as.data.frame(cbind(A,Y))
IPTW = mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
head(X)
## TMLE
#predict y give Ws
QbarSL = SL.pred
# get the predicted outcomes
QbarAW = predict(QbarSL, newdata=X)$pred
pred.g1W = gAW.sl$SL.predict
pred.g0W = 1- pred.g1W
gAW = ifelse(A==1, pred.g1W, pred.g0W)
# weights = 1/prob treatment
wt = 1/gAW
# Stabilized IPTW estimator
AY = as.data.frame(cbind(A,Y))
IPTW = mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
# generate the predicted prob of the obs experience, given baseline cov
gHatAW = rep(NA, nrow(final_data))
# Estimate g_0(A|W) with Super Learner
gHatSL = gAW.sl
# generate the predicted prob of being experienced, given baseline cov
gHat1W = pred.g1W
# generate the predicted prob of not being experienced, given baseline cov
gHat0W = pred.g0W
gHatAW[X$bullied==1]<- gHat1W[X$bullied==1]
gHatAW[X$bullied==0]<- gHat0W[X$bullied==0]
summary(gHatAW)
summary(gAW)
#Create the clever covariate H(A,W) for each subject
H.AW = as.numeric(X$bullied==1)/gHat1W - as.numeric(X$bullied==0)/gHat0W
PsiHat.IPTW <-mean( H.AW*Y)
ltmle.SL<- ltmle(data=X, Anodes='A', Ynodes='Y', abar=list(1,0), SL.library=SL.library)
## TMLE
WAY = cbind(X, Y)
names(WAY)
head(EAY)
head(WAY)
ltmle.SL<- ltmle(data=X, Anodes='bullied', Ynodes='Y', abar=list(1,0), SL.library=SL.library)
View(WAY)
ltmle.SL<- ltmle(data=X, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library)
ltmle.SL<- ltmle(data=X, Anodes=A, Ynodes=Y, abar=list(1,0), SL.library=SL.library)
ltmle.SL<- ltmle(data=X, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library)
ltmle.SL<- ltmle(data=X, Anodes="bullied", Ynodes=X$Y, abar=list(1,0), SL.library=SL.library)
## TMLE
WAY = cbind(X, as.numeric(Y))
ltmle.SL<- ltmle(data=X, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library)
## TMLE
WAY = cbind(X, Y)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library)
summary(ltmle.SL)
tmle.summary = summary(ltmle.SL)
TMLE = tmle.summary$effect.measures$ATE
TMLE
load("final_data_BMIz.RData")
set.seed(4864)
names(final_data)
##G-comp with SuperLearner
# Create SL library
SL.library = c("SL.glmnet", "SL.glm","SL.glm.interaction", "SL.randomForest")
# create dataset of Ws
X<- subset(final_data, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997"))
X$bullied=as.numeric(final_data$bullied_bf_12_1997)
X$bullied=ifelse(X$bullied==1,0,1)
# set treatment at 0 and 1
X0 = X
X0$bullied = 0
X1=X
X1$bullied = 1
# create a vector of Y
Y = as.numeric(final_data$ever_new_user2)
Y = ifelse(Y==1, 0, 1)
#run SL
SL.pred = SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1 = predict(SL.pred, newdata=X1)$pred
#g-comp for ATE
gComp = mean(predict.1-predict.0)
predict.0 = predict(SL.pred, newdata=X0)$pred
#g-comp for ATE
gComp = mean(predict.1-predict.0)
## Stabilized IPTW with SuperLearner
# make A a vector
A=as.numeric(final_data$bullied_bf_12_1997)
A=ifelse(A==1,0,1)
# just Ws
W = subset(X, select=c(1:5))
# estimate treatment mechanism
gAW.sl = SuperLearner(Y=A, X=W, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# estimate treatment mechanism
gAW.sl = SuperLearner(Y=A, X=W, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W = gAW.sl$SL.predict
pred.g0W = 1- pred.g1W
gAW = ifelse(A==1, pred.g1W, pred.g0W)
# weights = 1/prob treatment
wt = 1/gAW
# Stabilized IPTW estimator
AY = as.data.frame(cbind(A,Y))
IPTW = mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
## TMLE
WAY = cbind(X, Y)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library)
tmle.summary = summary(ltmle.SL)
TMLE = tmle.summary$effect.measures$ATE
TMLE
# unadjusted ATE
unadjusted = mean(WAY$Y[WAY$bullied==1]-WAY$Y[WAY$bullied==0])
# unadjusted ATE
unadjusted = mean(WAY$Y[WAY$bullied==1]) - mean(WAY$Y[WAY$bullied==0])
# performance of algorithms
ltmle.Sl
# performance of algorithms
ltmle.SL
View(ltmle.SL)
# performance of algorithms
SL.pred
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit") == TRUE)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit") == TRUE)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit"))
ltmle.SL$fit
# CV risk
CVrisk = CV.SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
CVrisk
summary(CVrisk)
my.est = mean(A * (Y/max(Y))/g0(W))/mean(A/g0(W))+1000
# 1) Run code in Rassign4_modifiedIPTW.R
set.seed(1)
# The true value of Qbar0(A,W) = E_0[Y|A,W]
Qbar0 = function(A,W){1000 + plogis(W*A)}
# The true value of g0(1|W) = Pr(A=1|W)
g0 = function(W){0.2 + 0.6*W}
# A function which returns a data frame with n i.i.d. observations from P0
gen.data = function(n){
W=rbinom(n,1,1/2)
A = rbinom(n,1,g0(W))
Y = 1000+rbinom(n,1,Qbar0(A,W)-1000)
return(data.frame(W=W,A=A,Y=Y))
}
# samples size
n= 1000
# Number of Monte Carlo draws
R = 2000
# Matrix of estimates from IPTW, modified Horvitz-Thompson, and my.est
est = matrix(NA,nrow=R,ncol=3)
colnames(est) = c('IPTW','Modifed HT','my.est')
ObsData = gen.data(n)
W = ObsData$W
A = ObsData$A
Y = ObsData$Y
my.est = mean(A * (Y/max(Y))/g0(W))/mean(A/g0(W))+1000
my.est = mean(A * (Y/max(Y))/g0(W))/mean(A/g0(W))*max(Y)
for(r in 1:R){
# Generate data with sample size
ObsData = gen.data(n)
W = ObsData$W
A = ObsData$A
Y = ObsData$Y
# IPTW estimate
IPTW.est = mean(A * Y/g0(W))
# Modified Horvitz-Thompson estimate
HT.est = mean(A * Y/g0(W))/mean(A/g0(W))
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y))/g0(W))/mean(A/g0(W))*max(Y)
# Put the estimates into the est matrix
est[r,] = c(IPTW.est,HT.est,my.est)
}
# Calculate the true value of EE[Y|A=1,W]
truth = 1/2*(Qbar0(1,0) + Qbar0(1,1))
# Calculate the estimated bias, variance, and MSE
est.bias = colMeans(est) - truth
est.var = apply(est,2,var)
est.mse = est.bias^2 + est.var
print(est.bias)
print(est.var)
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y))/g0(W))/mean(A/g0(W))*min(Y)
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y))/g0(W))/mean(A/g0(W))+min(Y)
# You should replace the NA below with your own estimate
my.est = mean(A * (Y-1000/g0(W))/mean(A/g0(W))+1000
# Put the estimates into the est matrix
est[r,] = c(IPTW.est,HT.est,my.est)
my.est = mean(A * (Y-1000/g0(W))/mean(A/g0(W))+1000
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))+1000
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))+1000)
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))*min(Y))
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))*max(Y))
for(r in 1:R){
# Generate data with sample size
ObsData = gen.data(n)
W = ObsData$W
A = ObsData$A
Y = ObsData$Y
# IPTW estimate
IPTW.est = mean(A * Y/g0(W))
# Modified Horvitz-Thompson estimate
HT.est = mean(A * Y/g0(W))/mean(A/g0(W))
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))+1000)
# Put the estimates into the est matrix
est[r,] = c(IPTW.est,HT.est,my.est)
}
for(r in 1:R){
# Generate data with sample size
ObsData = gen.data(n)
W = ObsData$W
A = ObsData$A
Y = ObsData$Y
# IPTW estimate
IPTW.est = mean(A * Y/g0(W))
# Modified Horvitz-Thompson estimate
HT.est = mean(A * Y/g0(W))/mean(A/g0(W))
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))+1000)
# Put the estimates into the est matrix
est[r,] = c(IPTW.est,HT.est,my.est)
}
# Calculate the true value of EE[Y|A=1,W]
truth = 1/2*(Qbar0(1,0) + Qbar0(1,1))
# Calculate the estimated bias, variance, and MSE
est.bias = colMeans(est) - truth
est.var = apply(est,2,var)
est.mse = est.bias^2 + est.var
print(est.bias)
print(est.var)
print(est.mse)
# 1) Run code in Rassign4_modifiedIPTW.R
set.seed(1)
# The true value of Qbar0(A,W) = E_0[Y|A,W]
Qbar0 = function(A,W){1000 + plogis(W*A)}
# The true value of g0(1|W) = Pr(A=1|W)
g0 = function(W){0.2 + 0.6*W}
# A function which returns a data frame with n i.i.d. observations from P0
gen.data = function(n){
W=rbinom(n,1,1/2)
A = rbinom(n,1,g0(W))
Y = 1000+rbinom(n,1,Qbar0(A,W)-1000)
return(data.frame(W=W,A=A,Y=Y))
}
# samples size
n= 1000
# Number of Monte Carlo draws
R = 2000
# Matrix of estimates from IPTW, modified Horvitz-Thompson, and my.est
est = matrix(NA,nrow=R,ncol=3)
colnames(est) = c('IPTW','Modifed HT','my.est')
for(r in 1:R){
# Generate data with sample size
ObsData = gen.data(n)
W = ObsData$W
A = ObsData$A
Y = ObsData$Y
# IPTW estimate
IPTW.est = mean(A * Y/g0(W))
# Modified Horvitz-Thompson estimate
HT.est = mean(A * Y/g0(W))/mean(A/g0(W))
# You should replace the NA below with your own estimate
my.est = mean(A * (Y/max(Y)/g0(W))/mean(A/g0(W))+1000)
# Put the estimates into the est matrix
est[r,] = c(IPTW.est,HT.est,my.est)
}
# Calculate the true value of EE[Y|A=1,W]
truth = 1/2*(Qbar0(1,0) + Qbar0(1,1))
# Calculate the estimated bias, variance, and MSE
est.bias = colMeans(est) - truth
est.var = apply(est,2,var)
est.mse = est.bias^2 + est.var
# Only can report estimated bias/variance/MSE because only took finitely many Monte Carlo draws (2000)
print('The estimators have (estimated) bias:')
print(est.bias)
print('The estimators have (estimated) variance:')
print(est.var)
print('The estimators have (estimated) MSE:')
print(est.mse)
