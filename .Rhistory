final_data$KEY_RACE_ETHNICITY_1997 <- as.factor(final_data$KEY_RACE_ETHNICITY_1997)
final_data$KEY_RACE_ETHNICITY_1997 <- revalue(final_data$KEY_RACE_ETHNICITY_1997,
c("1"="Black", "2"="Hispanic", "3"="MixedRace", "4"="White"))
#Decision was made to remove the Mixed Race group due to small numbers
final_data <- final_data %>% filter(KEY_RACE_ETHNICITY_1997 != "MixedRace")
final_data$KEY_RACE_ETHNICITY_1997 <- droplevels(final_data$KEY_RACE_ETHNICITY_1997) #takes away the empty category
final_data$KEY_SEX_1997 <- as.factor(final_data$KEY_SEX_1997)
final_data$KEY_SEX_1997 <- revalue(final_data$KEY_SEX_1997,
c("1"="M", "2"="F"))
final_data$anySameSex <- as.factor(final_data$anySameSex)
final_data$anySameSex <- revalue(final_data$anySameSex, c("FALSE" = "NoSameSex", "TRUE" = "SomeSameSex"))
final_data$learning_disability_1997 <- as.factor(final_data$learning_disability_1997)
final_data$learning_disability_1997  <- revalue(final_data$learning_disability_1997 , c("0" = "NoLearningDisability", "1" = "LearningDisability"))
final_data$CV_CITIZENSHIP_1997 <- as.factor(final_data$CV_CITIZENSHIP_1997)
final_data$CV_CITIZENSHIP_1997 <- revalue(final_data$CV_CITIZENSHIP_1997, c("1"="BornInUS", "2"="NotBornInUS", "3"="BirthplaceUnknown"))
final_data$anySameSex <- as.factor(final_data$anySameSex)
final_data$anySameSex <- revalue(final_data$anySameSex, c("1"="SameSex", "0"="NoSameSex"))
final_data$YOUTH_BOTHBIO.01_1997 <- as.factor(final_data$YOUTH_BOTHBIO.01_1997)
final_data$YOUTH_BOTHBIO.01_1997 <- revalue(final_data$YOUTH_BOTHBIO.01_1997, c("1"="LivesWBothBioParents", "0"="DoesntLiveWBioParents"))
final_data$overweight <- as.factor(final_data$overweight)
final_data$overweight <- revalue(final_data$overweight, c("0"="NotOverweight", "1"="Overweight"))
#Categorizing the Maternal Education variable
final_data$MomEducation <- NA
final_data$MomEducation[final_data$CV_HGC_BIO_MOM_1997 < 12] <- 0
final_data$MomEducation[final_data$CV_HGC_BIO_MOM_1997 == 12] <- 1
final_data$MomEducation[final_data$CV_HGC_BIO_MOM_1997 > 12] <- 2
final_data$MomEducation <-as.factor(final_data$MomEducation)
final_data$MomEducation <- revalue(final_data$MomEducation, c("0"="LessThanHigh", "1"="HighSchlGrad", "2"="SomeCollege"))
#dichotomous version of maternal education variable
final_data$MomEduDi <- NA
final_data$MomEduDi[final_data$CV_HGC_BIO_MOM_1997 < 12] <- 1
final_data$MomEduDi[final_data$CV_HGC_BIO_MOM_1997 == 12] <- 1
final_data$MomEduDi[final_data$CV_HGC_BIO_MOM_1997 > 12] <- 2
final_data$MomEduDi <-as.factor(final_data$MomEduDi)
final_data$MomEduDi <- revalue(final_data$MomEduDi, c("1"="HighSchlOrLess", "2"="SomeCollege"))
#Using CDC growth charts (via childsds package) to get BMI Z scores by age
final_data <-  final_data %>%
mutate(bmiz = sds(BMI,
age = KEY_AGE_1997,
sex = KEY_SEX_1997, male = "M", female =  "F",
ref = cdc.ref,
item = "bmi",
type = "SDS"))
#Note, there's one observation with a z score of -20, and some with -Inf (9 observations total)
#final_data %>% ggplot(aes(y=bmiz)) +geom_boxplot() #can uncomment this line to see the boxplot if desired
#We decided to exclude those 9 subjects, so
final_data <-  final_data %>% filter(bmiz> -15)
#Overweight variable based on pediatric criteria
final_data$PediOverweight<-"NotOverweight"
final_data$PediOverweight[final_data$bmiz > 1.036433] <-"Overweight" #because z of 1.036433 corresponds to 85th percentile, which is the definition of overweight in kids
final_data$PediOverweight <- as.factor(final_data$PediOverweight)
save(final_data, file = "final_data_BMIz.RData")
#just sexual orientation with exp/out. (Note that variables are releveled to put it into the format that epiR wants)
SexOrientTable <- table(relevel(final_data$bullied_bf_12_1997,2),relevel(final_data$ever_new_user2, 2),
final_data$anySameSex,
useNA="ifany")
#calculating test of homogeneity between strata of sexual orientation
epi.2by2(SexOrientTable)
#decision made to not use this variable based on small numbers, and no association with the measures of disease (looking at a test of homogeneity between strata)
#just learning/emotional problem with exp/out
LearningTable <- table(relevel(final_data$bullied_bf_12_1997,2),relevel(final_data$ever_new_user2, 2),
final_data$learning_disability_1997,
useNA="ifany")
#calculating test of homogeneity between strata of Learning/Emotional problems
epi.2by2(LearningTable)
#decision made to not use this variable because its learning or emotional problem at the time of the study (age 12-18), so this may not be temporally before the exposure and could actually be caused by exposure
#just citizenship with exp/out
CitizenTable <-table(relevel(final_data$bullied_bf_12_1997,2),relevel(final_data$ever_new_user2, 2),
final_data$CV_CITIZENSHIP_1997,
useNA="ifany")
#calculating test of homogeneity between strata of Citizenship (aka birthplace)
epi.2by2(CitizenTable)
#decision made to not use this variable because so few children were born outside the US and we're not sure if birthplace is really getting at the SES/hardship construct that we were trying to get with citizenship data
#Our set of variables
table(final_data$bullied_bf_12_1997,final_data$ever_new_user2,
final_data$KEY_RACE_ETHNICITY_1997,  final_data$KEY_SEX_1997,
final_data$MomEduDi,
final_data$PediOverweight, final_data$YOUTH_BOTHBIO.01_1997,
useNA="ifany")
#same set but no PediOverweight variable (considering it as a continuous instead)
table(final_data$bullied_bf_12_1997,final_data$ever_new_user2,
final_data$KEY_RACE_ETHNICITY_1997,  final_data$KEY_SEX_1997,
final_data$MomEduDi,
final_data$YOUTH_BOTHBIO.01_1997,
useNA="ifany")
#Density Plots for BMI
BMIbybullyingstatus <- final_data %>% filter(bmiz> -15) %>%
group_by( bullied_bf_12_1997) %>%
ggplot(aes(bmiz, fill = bullied_bf_12_1997)) +
geom_density(alpha=0.9) +
scale_fill_brewer(palette = 3)
#BMIbybullyingstatus
ggsave("BMIbybullyingstatus.pdf", BMIbybullyingstatus)
#Boxplots for BMI
BMIbybullyingstatusBox <- final_data %>% filter(bmiz> -15) %>%
group_by( bullied_bf_12_1997) %>%
ggplot(aes(y=bmiz, fill = bullied_bf_12_1997)) +
geom_boxplot()
#BMIbybullyingstatusBox
ggsave("BMIbybullyingstatusBox.pdf", BMIbybullyingstatusBox)
#7. Estimate
load("final_data_BMIz.RData")
set.seed(4864)
## prep data
# create dataset of Ws
X = subset(final_data, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997"))
# add A and make numeric
X$bullied=as.numeric(final_data$bullied_bf_12_1997)
X$bullied=ifelse(X$bullied==1,0,1)
# create a vector of Y
Y = as.numeric(final_data$ever_new_user2)
Y = ifelse(Y==1, 0, 1)
# write a parametric wrapper function to include in SL library
SL.loglinear = function (Y, X, newX, family, obsWeights, id) {
fit.loglin = glm(Y ~ ., data=X, family=poisson(link = "log"))
pred = predict(fit.loglin, newdata=newX, type='response')
fit = list(object=fit.loglin)
class(fit) = "SL.loglinear"
out <- list(pred = pred, fit = fit)
return(out)
}
predict.SL.loglinear <- function(object, newdata, ...) {
# newdata must be a dataframe, not a matrix.
if (is.matrix(newdata)) {
newdata = as.data.frame(newdata)
}
pred <- predict(object = object$object, newdata = newdata, type = "response")
pred
}
# Create SL library
SL.library = c("SL.glm","SL.glm.interaction","SL.glmnet", "SL.bayesglm", "SL.randomForest",  "SL.step", "SL.mean", "SL.loglinear")
##G-comp with SuperLearner##
# set treatment at 0 and 1
X0 = X
X0$bullied = 0
X1=X
X1$bullied = 1
#run SL
SL.pred = SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1 = predict(SL.pred, newdata=X1)$pred
predict.0 = predict(SL.pred, newdata=X0)$pred
#g-comp for ATE
gComp = mean(predict.1-predict.0)
## Stabilized IPTW with SuperLearner ##
# make A a vector
A=X$bullied
# just Ws
W = subset(X, select=c(1:5))
# estimate treatment mechanism
gAW.sl = SuperLearner(Y=A, X=W, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W = gAW.sl$SL.predict
pred.g0W = 1- pred.g1W
gAW = ifelse(A==1, pred.g1W, pred.g0W)
# weights = 1/prob treatment
wt = 1/gAW
# Stabilized IPTW estimator
AY = as.data.frame(cbind(A,Y))
IPTW = mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
## TMLE ##
WAY = cbind(X, Y)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit"))
tmle.summary = summary(ltmle.SL)
TMLE = tmle.summary$effect.measures$ATE
# performance of algorithms
ltmle.SL$fit
# CV risk
CVrisk = CV.SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
CVsummary = summary(CVrisk)
CVtable = CVsummary$Table
## unadjusted ATE ##
unadjusted = mean(WAY$Y[WAY$bullied==1]) - mean(WAY$Y[WAY$bullied==0])
```{r bootstrap}
#breaking the boostrap into ten sections to make this easier on my little laptop
set.seed(252)
#section1#####
#set the number of bootstrap iterations (B)
B <- 1000
#set the total number in our sample
n <- nrow(WAY)
numCores <- detectCores()  #detect number of processor cores on the computer
registerDoParallel(numCores)  # use multicore, set to the number of cores on this computer
BootstrappedEsts1 <- foreach (b=1:B, .combine=rbind, .packages='SuperLearner') %dopar% {
#this is just a paralellized  version of a for loop
#these create a new single sample which was resampled (with replacement)from our original sample
bootIndices<- sample(1:n, replace=T)
bootData<- WAY[bootIndices,]
#From here to almost the end of the function is just Veronica's code from above but with all the various bits renamed to bootstrapped versions
# write a parametric wrapper function to include in SL library
# Create SL library
SL.library = c("SL.glm","SL.glm.interaction","SL.glmnet", "SL.bayesglm", "SL.randomForest",  "SL.step", "SL.mean")
##G-comp with SuperLearner##
# set treatment at 0 and 1
X0.boot = bootData
X0.boot$bullied = 0
X1.boot=bootData
X1.boot$bullied = 1
#create a dataset with just the A and Ws
WA.boot <- subset(bootData, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997", "bullied"))
#run SL
SL.pred.boot = SuperLearner(Y=bootData$Y, X=WA.boot, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1.boot = predict(SL.pred.boot, newdata=X1.boot)$pred
predict.0.boot = predict(SL.pred.boot, newdata=X0.boot)$pred
#g-comp for ATE
gComp.boot = mean(predict.1.boot-predict.0.boot)
## Stabilized IPTW with SuperLearner ##
# make A a vector
A.boot=bootData$bullied
# just Ws
W.boot = subset(bootData, select=c(1:5))
# estimate treatment mechanism
gAW.sl.boot = SuperLearner(Y=A.boot, X=W.boot, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W.boot = gAW.sl.boot$SL.predict
pred.g0W.boot = 1- pred.g1W.boot
gAW.boot = ifelse(A==1, pred.g1W.boot, pred.g0W.boot)
# weights = 1/prob treatment
wt.boot = 1/gAW.boot
# Stabilized IPTW estimator
AY.boot = as.data.frame(cbind(A.boot,Y.boot=bootData$Y))
IPTW.boot = mean( wt*as.numeric(AY.boot$A.boot==1)*AY.boot$Y.boot)/mean( wt*as.numeric(AY.boot$A.boot==1)) -
mean( wt*as.numeric(AY.boot$A.boot==0)*AY.boot$Y.boot)/mean(wt*as.numeric(AY.boot$A.boot==0))
## TMLE ##
# ltmle.SL.boot<- ltmle(data=bootData, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit"))
# tmle.summary.boot = summary(ltmle.SL.boot)
# TMLE.boot = tmle.summary.boot$effect.measures$ATE
c(gComp.boot, IPTW.boot)
}
install.packages("doRNG")
library(doRNG)
install.packages("rngtools")
install.packages("Rtools")
install.packages("rtools")
install.packages("rngtools")
library("doRNG")
install.packages("rngtools")
install.packages("updateR")
install.packages("rng-tools")
install.packages("installr")
library(installr)
UpdateR()
updateR()
library(plyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(childsds)
library(epiR)
library(SuperLearner)
library(ltmle)
library(knitr)
library(tidyr)
#these two packages allow for paralellization of the analysis using multiple computer processor cores
library(foreach)
library(doParallel)
library(doRNG) #you need a particular package in order to make paralellization reproducible...eyeroll
install.packages("doRNG")
install.packages("rngtools")
library(plyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(childsds)
library(epiR)
library(SuperLearner)
library(ltmle)
library(knitr)
library(tidyr)
knitr::opts_chunk$set(include = FALSE, cache = TRUE)
# First, load the data
ShelleyStephLizzyVeronicaDataLoad <- function(filename)
{
if(Sys.info()['sysname']=="Darwin"){
macfilepath <- paste("./NLSY Data/", filename, sep = "")
load(as.character(macfilepath), envir = globalenv())}
else{
if(Sys.info()['login']=="Peter"){
peterfilepath <- paste("~/Steph/GitHub/finalproject/NLSY Data/", filename, sep = "")
load(as.character(peterfilepath), envir = globalenv())}
else{
windowsfilepath <- paste("~/GitHub/finalproject/NLSY Data/", filename, sep = "")
load(as.character(windowsfilepath), envir = globalenv())
}
}
}
ShelleyStephLizzyVeronicaDataLoad("imputed_data.Rdata")
final_data <- imputed_data
rm(imputed_data)
load("BootstrappedEstsFirst800.RData")
#make a long data version of the bootstrapped estimates to be able to plot them together on one histogram/density plot
Bootstrapped_long <- gather(BootstrappedEstsFirst800, Estimator, value, gCompBoot:IPTWboot)
BootstrappedHist <- Bootstrapped_long %>% group_by(Estimator) %>%
ggplot(aes(value, fill = Estimator)) +
geom_histogram(color = "black", binwidth = 0.0005, size = 0.1) +
scale_fill_brewer(palette = 5, labels = c("G-comp", "IPTW")) +
scale_x_continuous(limits = c(0,0.1)) +
xlab("Average Treatment Effect Value") +
theme(legend.title=element_blank()) +
ggtitle("Histograms of G-comp and IPTW Estimands \n From 800 Bootstrap Repetitions")
#little for loop to create confidence interval for each of the two estimators based on our bootstrapped data
CIs <-matrix(rep(NA, 6), nrow = 2, ncol = 2)
for (c in 1:2){
CI.quant  <- quantile(BootstrappedEstsFirst800[ ,c], prob=c(0.025,0.975))
CIs[c,] <- CI.quant
}
rownames(CIs) <-c("Gcomp","IPTW")
colnames(CIs) <-c("95% CI Lower Limit", "95% CI Upper Limit")
library(plyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(childsds)
library(epiR)
library(SuperLearner)
library(ltmle)
library(knitr)
library(tidyr)
knitr::opts_chunk$set(include = FALSE, cache = TRUE)
# First, load the data
ShelleyStephLizzyVeronicaDataLoad <- function(filename)
{
if(Sys.info()['sysname']=="Darwin"){
macfilepath <- paste("./NLSY Data/", filename, sep = "")
load(as.character(macfilepath), envir = globalenv())}
else{
if(Sys.info()['login']=="Peter"){
peterfilepath <- paste("~/Steph/GitHub/finalproject/NLSY Data/", filename, sep = "")
load(as.character(peterfilepath), envir = globalenv())}
else{
windowsfilepath <- paste("~/GitHub/finalproject/NLSY Data/", filename, sep = "")
load(as.character(windowsfilepath), envir = globalenv())
}
}
}
ShelleyStephLizzyVeronicaDataLoad("imputed_data.Rdata")
final_data <- imputed_data
rm(imputed_data)
#7. Estimate
load("final_data_BMIz.RData")
set.seed(4864)
## prep data
# create dataset of Ws
X = subset(final_data, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997"))
# add A and make numeric
X$bullied=as.numeric(final_data$bullied_bf_12_1997)
X$bullied=ifelse(X$bullied==1,0,1)
# create a vector of Y
Y = as.numeric(final_data$ever_new_user2)
Y = ifelse(Y==1, 0, 1)
# write a parametric wrapper function to include in SL library
SL.loglinear = function (Y, X, newX, family, obsWeights, id) {
fit.loglin = glm(Y ~ ., data=X, family=poisson(link = "log"))
pred = predict(fit.loglin, newdata=newX, type='response')
fit = list(object=fit.loglin)
class(fit) = "SL.loglinear"
out <- list(pred = pred, fit = fit)
return(out)
}
predict.SL.loglinear <- function(object, newdata, ...) {
# newdata must be a dataframe, not a matrix.
if (is.matrix(newdata)) {
newdata = as.data.frame(newdata)
}
pred <- predict(object = object$object, newdata = newdata, type = "response")
pred
}
# Create SL library
SL.library = c("SL.glm","SL.glm.interaction","SL.glmnet", "SL.bayesglm", "SL.randomForest",  "SL.step", "SL.mean", "SL.loglinear")
##G-comp with SuperLearner##
# set treatment at 0 and 1
X0 = X
X0$bullied = 0
X1=X
X1$bullied = 1
#run SL
SL.pred = SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# get predicted outcomes under both scenarios
predict.1 = predict(SL.pred, newdata=X1)$pred
predict.0 = predict(SL.pred, newdata=X0)$pred
#g-comp for ATE
gComp = mean(predict.1-predict.0)
## Stabilized IPTW with SuperLearner ##
# make A a vector
A=X$bullied
# just Ws
W = subset(X, select=c(1:5))
# estimate treatment mechanism
gAW.sl = SuperLearner(Y=A, X=W, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W = gAW.sl$SL.predict
pred.g0W = 1- pred.g1W
gAW = ifelse(A==1, pred.g1W, pred.g0W)
# weights = 1/prob treatment
wt = 1/gAW
# Stabilized IPTW estimator
AY = as.data.frame(cbind(A,Y))
IPTW = mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))
## TMLE ##
WAY = cbind(X, Y)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit"))
tmle.summary = summary(ltmle.SL)
TMLE = tmle.summary$effect.measures$ATE
# performance of algorithms
ltmle.SL$fit
# CV risk
CVrisk = CV.SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
CVsummary = summary(CVrisk)
CVtable = CVsummary$Table
## unadjusted ATE ##
unadjusted = mean(WAY$Y[WAY$bullied==1]) - mean(WAY$Y[WAY$bullied==0])
PositivityData <- WAY
PositivityData$gAW <- gAW
IPTWDensityPlot <- PositivityData %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(position="identity") +
scale_fill_brewer(palette = 3) +
scale_x_continuous(limits = c(0,2.5)) +
xlab("Probability of AW") +
theme(legend.title=element_blank()) +
ggtitle("Density Plot of AW Probabilities By Outcome Group")
IPTWDensityPlot
IPTWDensityPlot <- PositivityData %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(position="identity") +
scale_fill_brewer(palette = 3) +
scale_x_continuous(limits = c(0,1)) +
xlab("Probability of AW") +
theme(legend.title=element_blank()) +
ggtitle("Density Plot of AW Probabilities By Outcome Group")
IPTWDensityPlot
BMIbybullyingstatus <- final_data %>% filter(bmiz> -15) %>%
group_by( bullied_bf_12_1997) %>%
ggplot(aes(bmiz, fill = bullied_bf_12_1997)) +
geom_density(alpha=0.9) +
scale_fill_brewer(palette = 3)
BMIbybullyingstatus
View(PositivityData)
summary(PositivityData$Y)
summary(PositivityData$gAW)
PositivityData %>% group_by(Y) %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(alpha=0.9) +
scale_fill_brewer(palette = 3)
IPTWDensityPlot <- PositivityData %>% group_by(Y) %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(alpha=0.9) +
scale_fill_brewer(palette = 3)
IPTWDensityPlot
PositivityData$Y <- as.factor(PositivityData$Y)
IPTWDensityPlot <- PositivityData %>% group_by(Y) %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(alpha=0.9) +
scale_fill_brewer(palette = 3)
IPTWDensityPlot
IPTWDensityPlot <- PositivityData %>% group_by(Y) %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(alpha=0.7) +
scale_fill_brewer(palette = 3) +
scale_x_continuous(limits = c(0,1)) +
xlab("Probability of AW") +
theme(legend.title=element_blank()) +
ggtitle("Density Plot of AW Probabilities By Outcome Group")
IPTWDensityPlot
IPTWDensityPlot <- PositivityData %>% group_by(Y) %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(alpha=0.4) +
scale_fill_brewer(palette = 3, labels = c("No drug use", "Drug Use")) +
scale_x_continuous(limits = c(0,1)) +
xlab("Probability of AW") +
theme(legend.title=element_blank()) +
ggtitle("Density Plot of AW Probabilities By Outcome Group")
IPTWDensityPlot
gAWBox <- ggplot(aes(y=gAW)) + geom_boxplot()
gAWBox <- as.data.frame(gAW) %>% ggplot(aes(y= gAW)) + geom_boxplot()
gAWBox
BootstrappedHist <- Bootstrapped_long %>% group_by(Estimator) %>%
ggplot(aes(value, fill = Estimator)) +
geom_histogram(color = "black", binwidth = 0.0005, size = 0.1) +
scale_fill_brewer(palette = 5, labels = c("G-comp", "IPTW")) +
scale_x_continuous(limits = c(0,0.1)) +
xlab("Average Treatment Effect Value") +
theme(legend.title=element_blank()) +
ggtitle("Histograms of G-comp and IPTW Estimands \n From 800 Bootstrap Repetitions") +
theme(text = element_text(size = 16))
BMIbybullyingstatus <- final_data %>% filter(bmiz> -15) %>%
group_by( bullied_bf_12_1997) %>%
ggplot(aes(bmiz, fill = bullied_bf_12_1997)) +
geom_density(alpha=0.9) +
scale_fill_brewer(palette = 3) +
theme(text = element_text(size = 30))
BootstrappedHist <- Bootstrapped_long %>% group_by(Estimator) %>%
ggplot(aes(value, fill = Estimator)) +
geom_histogram(color = "black", binwidth = 0.0005, size = 0.1) +
scale_fill_brewer(palette = 5, labels = c("G-comp", "IPTW")) +
scale_x_continuous(limits = c(0,0.1)) +
xlab("Average Treatment Effect Value") +
theme(legend.title=element_blank()) +
ggtitle("Histograms of G-comp and IPTW Estimands \n From 800 Bootstrap Repetitions") +
theme(text = element_text(size = 30))
IPTWDensityPlot <- PositivityData %>% group_by(Y) %>%
ggplot(aes(gAW, fill = Y)) +
geom_density(alpha=0.4) +
scale_fill_brewer(palette = 3, labels = c("No drug use", "Drug Use")) +
scale_x_continuous(limits = c(0,1)) +
xlab("Probability of AW") +
theme(legend.title=element_blank()) +
ggtitle("Density Plot of AW Probabilities By Outcome Group") +
theme(text = element_text(size = 30))
