---
title: "Final Project: \n Childhood Bullying and Subsequent Drug Use"
author: "Shelley Facente, Steph Holm, Lizzy Kinnard, Veronica Pear"
output:
  beamer_presentation: default
date: "Spring 2019"
---

```{r setup, include=FALSE}
library(plyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(childsds)
library(epiR)
library(SuperLearner)
library(ltmle)
library(knitr)
library(tidyr)

#these two packages allow for paralellization of the analysis using multiple computer processor cores
library(foreach)
library(doParallel)
library(doRNG) #you need a particular package in order to make paralellization reproducible...eyeroll 

knitr::opts_chunk$set(include = FALSE, cache = TRUE)

# First, load the data
ShelleyStephLizzyVeronicaDataLoad <- function(filename) 
{
  if(Sys.info()['sysname']=="Darwin"){
    macfilepath <- paste("./NLSY Data/", filename, sep = "")
     load(as.character(macfilepath), envir = globalenv())}
  else{
    if(Sys.info()['login']=="Peter"){
    peterfilepath <- paste("~/Steph/GitHub/finalproject/NLSY Data/", filename, sep = "")
     load(as.character(peterfilepath), envir = globalenv())}
  else{
    windowsfilepath <- paste("~/GitHub/finalproject/NLSY Data/", filename, sep = "")
     load(as.character(windowsfilepath), envir = globalenv())
  }
}
}

ShelleyStephLizzyVeronicaDataLoad("imputed_data.Rdata")
final_data <- imputed_data
rm(imputed_data)
```



```{r data cleaning}
#Let's do all Variable prep/Data cleaning in this chunk

#some cleaning of variables to rename levels for ease of visualization
final_data$bullied_bf_12_1997 <- as.factor(final_data$bullied_bf_12_1997)
final_data$bullied_bf_12_1997 <- revalue(final_data$bullied_bf_12_1997,    
                                         c("0"="NotBullied", "1"="Bullied"))

final_data$ever_new_user2 <- as.factor(final_data$ever_new_user2)
final_data$ever_new_user2 <- revalue( final_data$ever_new_user2,
                                      c("0" = "NoDrugUse", "1" = "DrugUse"))

final_data$KEY_RACE_ETHNICITY_1997 <- as.factor(final_data$KEY_RACE_ETHNICITY_1997)
final_data$KEY_RACE_ETHNICITY_1997 <- revalue(final_data$KEY_RACE_ETHNICITY_1997,    
                                         c("1"="Black", "2"="Hispanic", "3"="MixedRace", "4"="White"))

#Decision was made to remove the Mixed Race group due to small numbers
final_data <- final_data %>% filter(KEY_RACE_ETHNICITY_1997 != "MixedRace")
final_data$KEY_RACE_ETHNICITY_1997 <- droplevels(final_data$KEY_RACE_ETHNICITY_1997) #takes away the empty category

final_data$KEY_SEX_1997 <- as.factor(final_data$KEY_SEX_1997)
final_data$KEY_SEX_1997 <- revalue(final_data$KEY_SEX_1997,    
                                         c("1"="M", "2"="F"))

final_data$anySameSex <- as.factor(final_data$anySameSex)
final_data$anySameSex <- revalue(final_data$anySameSex, c("FALSE" = "NoSameSex", "TRUE" = "SomeSameSex"))

final_data$learning_disability_1997 <- as.factor(final_data$learning_disability_1997)
final_data$learning_disability_1997  <- revalue(final_data$learning_disability_1997 , c("0" = "NoLearningDisability", "1" = "LearningDisability"))

final_data$CV_CITIZENSHIP_1997 <- as.factor(final_data$CV_CITIZENSHIP_1997)
final_data$CV_CITIZENSHIP_1997 <- revalue(final_data$CV_CITIZENSHIP_1997, c("1"="BornInUS", "2"="NotBornInUS", "3"="BirthplaceUnknown"))

final_data$anySameSex <- as.factor(final_data$anySameSex)
final_data$anySameSex <- revalue(final_data$anySameSex, c("1"="SameSex", "0"="NoSameSex"))

final_data$YOUTH_BOTHBIO.01_1997 <- as.factor(final_data$YOUTH_BOTHBIO.01_1997)
final_data$YOUTH_BOTHBIO.01_1997 <- revalue(final_data$YOUTH_BOTHBIO.01_1997, c("1"="LivesWBothBioParents", "0"="DoesntLiveWBioParents"))

final_data$overweight <- as.factor(final_data$overweight)
final_data$overweight <- revalue(final_data$overweight, c("0"="NotOverweight", "1"="Overweight"))


#Categorizing the Maternal Education variable
final_data$MomEducation <- NA
final_data$MomEducation[final_data$CV_HGC_BIO_MOM_1997 < 12] <- 0
final_data$MomEducation[final_data$CV_HGC_BIO_MOM_1997 == 12] <- 1
final_data$MomEducation[final_data$CV_HGC_BIO_MOM_1997 > 12] <- 2
final_data$MomEducation <-as.factor(final_data$MomEducation)
final_data$MomEducation <- revalue(final_data$MomEducation, c("0"="LessThanHigh", "1"="HighSchlGrad", "2"="SomeCollege"))

#dichotomous version of maternal education variable
final_data$MomEduDi <- NA
final_data$MomEduDi[final_data$CV_HGC_BIO_MOM_1997 < 12] <- 1
final_data$MomEduDi[final_data$CV_HGC_BIO_MOM_1997 == 12] <- 1
final_data$MomEduDi[final_data$CV_HGC_BIO_MOM_1997 > 12] <- 2
final_data$MomEduDi <-as.factor(final_data$MomEduDi)
final_data$MomEduDi <- revalue(final_data$MomEduDi, c("1"="HighSchlOrLess", "2"="SomeCollege"))

#Using CDC growth charts (via childsds package) to get BMI Z scores by age 

 final_data <-  final_data %>%
                    mutate(bmiz = sds(BMI,
                    age = KEY_AGE_1997,
                    sex = KEY_SEX_1997, male = "M", female =  "F",
                    ref = cdc.ref,
                    item = "bmi",
                    type = "SDS"))
 
 #Note, there's one observation with a z score of -20, and some with -Inf (9 observations total)
 #final_data %>% ggplot(aes(y=bmiz)) +geom_boxplot() #can uncomment this line to see the boxplot if desired
 #We decided to exclude those 9 subjects, so
 final_data <-  final_data %>% filter(bmiz> -15) 
  
  #Overweight variable based on pediatric criteria
  final_data$PediOverweight<-"NotOverweight"
  final_data$PediOverweight[final_data$bmiz > 1.036433] <-"Overweight" #because z of 1.036433 corresponds to 85th percentile, which is the definition of overweight in kids
 final_data$PediOverweight <- as.factor(final_data$PediOverweight)
 
 save(final_data, file = "final_data_BMIz.RData")
 
```




```{r positivity checking}


#just sexual orientation with exp/out. (Note that variables are releveled to put it into the format that epiR wants)
SexOrientTable <- table(relevel(final_data$bullied_bf_12_1997,2),relevel(final_data$ever_new_user2, 2),
                   final_data$anySameSex, 
                   useNA="ifany")

#calculating test of homogeneity between strata of sexual orientation
epi.2by2(SexOrientTable)
#decision made to not use this variable based on small numbers, and no association with the measures of disease (looking at a test of homogeneity between strata)

#just learning/emotional problem with exp/out
LearningTable <- table(relevel(final_data$bullied_bf_12_1997,2),relevel(final_data$ever_new_user2, 2),
      final_data$learning_disability_1997, 
      useNA="ifany")

#calculating test of homogeneity between strata of Learning/Emotional problems 
epi.2by2(LearningTable)
#decision made to not use this variable because its learning or emotional problem at the time of the study (age 12-18), so this may not be temporally before the exposure and could actually be caused by exposure

#just citizenship with exp/out
CitizenTable <-table(relevel(final_data$bullied_bf_12_1997,2),relevel(final_data$ever_new_user2, 2),
      final_data$CV_CITIZENSHIP_1997,
      useNA="ifany")

#calculating test of homogeneity between strata of Citizenship (aka birthplace)
epi.2by2(CitizenTable)
#decision made to not use this variable because so few children were born outside the US and we're not sure if birthplace is really getting at the SES/hardship construct that we were trying to get with citizenship data


#Our set of variables
table(final_data$bullied_bf_12_1997,final_data$ever_new_user2,
      final_data$KEY_RACE_ETHNICITY_1997,  final_data$KEY_SEX_1997,
      final_data$MomEduDi, 
      final_data$PediOverweight, final_data$YOUTH_BOTHBIO.01_1997,
      useNA="ifany")

#same set but no PediOverweight variable (considering it as a continuous instead)
table(final_data$bullied_bf_12_1997,final_data$ever_new_user2,
      final_data$KEY_RACE_ETHNICITY_1997,  final_data$KEY_SEX_1997,
      final_data$MomEduDi, 
      final_data$YOUTH_BOTHBIO.01_1997,
      useNA="ifany")

#Density Plots for BMI
BMIbybullyingstatus <- final_data %>% filter(bmiz> -15) %>%
                        group_by( bullied_bf_12_1997) %>% 
                        ggplot(aes(bmiz, fill = bullied_bf_12_1997)) +
                          geom_density(alpha=0.9) +
                          scale_fill_brewer(palette = 3)
#BMIbybullyingstatus
ggsave("BMIbybullyingstatus.pdf", BMIbybullyingstatus)

#Boxplots for BMI
BMIbybullyingstatusBox <- final_data %>% filter(bmiz> -15) %>%
                        group_by( bullied_bf_12_1997) %>% 
                        ggplot(aes(y=bmiz, fill = bullied_bf_12_1997)) +
                          geom_boxplot() 
#BMIbybullyingstatusBox
ggsave("BMIbybullyingstatusBox.pdf", BMIbybullyingstatusBox)

```


``` {r estimate, cache = TRUE}
#7. Estimate
load("final_data_BMIz.RData")
set.seed(4864)

## prep data

# create dataset of Ws
X = subset(final_data, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997"))

# add A and make numeric
X$bullied=as.numeric(final_data$bullied_bf_12_1997)
X$bullied=ifelse(X$bullied==1,0,1)

# create a vector of Y
Y = as.numeric(final_data$ever_new_user2)
Y = ifelse(Y==1, 0, 1)

# write a parametric wrapper function to include in SL library
SL.loglinear = function (Y, X, newX, family, obsWeights, id) {
    fit.loglin = glm(Y ~ ., data=X, family=poisson(link = "log"))
    pred = predict(fit.loglin, newdata=newX, type='response')
    fit = list(object=fit.loglin)
    class(fit) = "SL.loglinear"
    out <- list(pred = pred, fit = fit)
    return(out)
}
predict.SL.loglinear <- function(object, newdata, ...) {
  # newdata must be a dataframe, not a matrix.
  if (is.matrix(newdata)) {
    newdata = as.data.frame(newdata)
  }
  pred <- predict(object = object$object, newdata = newdata, type = "response")
  pred
}

# Create SL library
SL.library = c("SL.glm","SL.glm.interaction","SL.glmnet", "SL.bayesglm", "SL.randomForest",  "SL.step", "SL.mean", "SL.loglinear")


##G-comp with SuperLearner##

# set treatment at 0 and 1
X0 = X
X0$bullied = 0

X1=X
X1$bullied = 1

#run SL 
SL.pred = SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))

# get predicted outcomes under both scenarios
predict.1 = predict(SL.pred, newdata=X1)$pred
predict.0 = predict(SL.pred, newdata=X0)$pred

#g-comp for ATE
gComp = mean(predict.1-predict.0)


## Stabilized IPTW with SuperLearner ##

# make A a vector
A=X$bullied
# just Ws
W = subset(X, select=c(1:5))

# estimate treatment mechanism
gAW.sl = SuperLearner(Y=A, X=W, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W = gAW.sl$SL.predict 
pred.g0W = 1- pred.g1W
gAW = ifelse(A==1, pred.g1W, pred.g0W)
# weights = 1/prob treatment
wt = 1/gAW
# Stabilized IPTW estimator 
AY = as.data.frame(cbind(A,Y))
IPTW = mean( wt*as.numeric(AY$A==1)*AY$Y)/mean( wt*as.numeric(AY$A==1)) -
mean( wt*as.numeric(AY$A==0)*AY$Y)/mean( wt*as.numeric(AY$A==0))


## TMLE ##

WAY = cbind(X, Y)
ltmle.SL<- ltmle(data=WAY, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit"))
tmle.summary = summary(ltmle.SL)
TMLE = tmle.summary$effect.measures$ATE
# performance of algorithms
ltmle.SL$fit
# CV risk
CVrisk = CV.SuperLearner(Y=Y, X=X, SL.library=SL.library, family='binomial', cvControl=list(V=5))
CVsummary = summary(CVrisk)
CVtable = CVsummary$Table

## unadjusted ATE ##
unadjusted = mean(WAY$Y[WAY$bullied==1]) - mean(WAY$Y[WAY$bullied==0])


```



```{r bootstrap}
#breaking the boostrap into ten sections to make this easier on my little laptop
set.seed(252)

#section1#####
#set the number of bootstrap iterations (B)
B <- 8

#set the total number in our sample
n <- nrow(WAY)


numCores <- detectCores()  #detect number of processor cores on the computer
registerDoParallel(numCores)  # use multicore, set to the number of cores on this computer

BootstrappedEsts <- foreach (b=1:B, .combine=rbind, .packages='SuperLearner') %dorng% { 
  #this is just a paralellized  version of a for loop
  
#these create a new single sample which was resampled (with replacement)from our original sample
bootIndices<- sample(1:n, replace=T)
bootData<- WAY[bootIndices,]

#From here to almost the end of the function is just Veronica's code from above but with all the various bits renamed to bootstrapped versions


# Create SL library
SL.library = c("SL.glm","SL.glm.interaction","SL.glmnet", "SL.bayesglm", "SL.randomForest",  "SL.step", "SL.mean")


  ##G-comp with SuperLearner##

# set treatment at 0 and 1
X0.boot = bootData
X0.boot$bullied = 0

X1.boot=bootData
X1.boot$bullied = 1

#create a dataset with just the A and Ws
WA.boot <- subset(bootData, select=c("KEY_RACE_ETHNICITY_1997", "KEY_SEX_1997","bmiz", "MomEduDi", "YOUTH_BOTHBIO.01_1997", "bullied"))

#run SL 
SL.pred.boot = SuperLearner(Y=bootData$Y, X=WA.boot, SL.library=SL.library, family='binomial', cvControl=list(V=5))

# get predicted outcomes under both scenarios
predict.1.boot = predict(SL.pred.boot, newdata=X1.boot)$pred
predict.0.boot = predict(SL.pred.boot, newdata=X0.boot)$pred

#g-comp for ATE
gComp.boot = mean(predict.1.boot-predict.0.boot)


## Stabilized IPTW with SuperLearner ##

# make A a vector
A.boot=bootData$bullied
# just Ws
W.boot = subset(bootData, select=c(1:5))

# estimate treatment mechanism
gAW.sl.boot = SuperLearner(Y=A.boot, X=W.boot, SL.library=SL.library, family='binomial', cvControl=list(V=5))
# predicted prob of observed treatment
pred.g1W.boot = gAW.sl.boot$SL.predict 
pred.g0W.boot = 1- pred.g1W.boot
gAW.boot = ifelse(A==1, pred.g1W.boot, pred.g0W.boot)
# weights = 1/prob treatment
wt.boot = 1/gAW.boot
# Stabilized IPTW estimator 
AY.boot = as.data.frame(cbind(A.boot,Y.boot=bootData$Y))
IPTW.boot = mean( wt*as.numeric(AY.boot$A.boot==1)*AY.boot$Y.boot)/mean( wt*as.numeric(AY.boot$A.boot==1)) -
mean( wt*as.numeric(AY.boot$A.boot==0)*AY.boot$Y.boot)/mean(wt*as.numeric(AY.boot$A.boot==0))


## TMLE ##

# ltmle.SL.boot<- ltmle(data=bootData, Anodes="bullied", Ynodes="Y", abar=list(1,0), SL.library=SL.library, attr(SL.library, "return.fit"))
# tmle.summary.boot = summary(ltmle.SL.boot)
# TMLE.boot = tmle.summary.boot$effect.measures$ATE


  c(gComp.boot, IPTW.boot)
}



save(BootstrappedEsts, file = "BootstrappedEsts.RData")

#make a long data version of the bootstrapped estimates to be able to plot them together on one histogram/density plot
Bootstrapped_long <- gather(BootstrappedEsts, Estimator, value, gCompBoot:IPTWboot)

BootstrappedHist <- Bootstrapped_long %>%
    ggplot() +
    geom_histogram(aes(value)) +
    facet_wrap(~Estimator)

#little for loop to create confidence interval for each of the two estimators based on our bootstrapped data
CIs <-matrix(rep(NA, 6), nrow = 2, ncol = 2)
for (c in 1:2){
   CI.quant  <- quantile(BootstrappedEsts[ ,c], prob=c(0.025,0.975))
   CIs[c,] <- CI.quant
}

```


## Structural Causal Model
<!-- note that we can add comments like this that won't knit --> 

<!-- All this below is just adapted from our proposal. --> 


## Causal Question: What is the effect of having been bullied prior to age 12 on incidence of drug use in adolescence or adulthood?

## Target Causal Parameter:

  - Difference in the counterfactual probability of drug use if all kids were bullied prior to age 12, and the counterfactual probability of drug use if all kids were not bullied prior to age 12:

$$
\psi^F (P_{U,X}) = P_{U,X} (Y_1 = 1) - P_{{U,X}}(Y_0=1) = E_{U,X}(Y_1) - E_{U,X}(Y_0)
$$
where $Y_a$ denotes the counterfactual outcome under an intervention to set bullying status A = a.

## Our Observed Data and Link to SCM

  - Data are from the National Longitudinal Survey of Youth 1997
  - A nationally representative cohort of youth age 12-16 (initial n=9000) in 1997, who were subsequently followed longitudinally. 
  - The target population is youth in the United States.

## Data Description: 
Key variables:

A: Bullying before the age of 12 (asked in 1997)

Y: Incident drug use ("cocaine or other hard drugs") after 1997

W: Race/ethnicity, age, sex, BMI, not living with both biological parents, mother's educational status (all Ws were measured at baseline)

Sample size: 7,703

We initially also considered: sexual orientation, learning/emotional disability, citizenship status

## Marginal distribution of exposure and outcome:

```{r, include=FALSE}
#marginal distribution of exposure
exposure = table(final_data$bullied_bf_12_1997, useNA="ifany")

#marginal distribution of outcome
outcome = table(final_data$ever_new_user2, useNA = "ifany")
```
Variable | No | Yes 
-------- | ------- | -------
Bullied < 12 | `r exposure[1]` | `r exposure[2]`
Incident drug use | `r outcome[1]` | `r outcome[2]`


## Identifiability


## Estimand and Statistical Model
```{r, include=TRUE, echo=TRUE}
#just here as an example of a code chunk
mean(Y)
```

## Estimation: Unadjusted ATE & SuperLearner

- The unadjusted ATE = mean(Y|A=1 - Y|A=0) = `r round(unadjusted, 3)`

- We use SuperLearner for prediction in all models. 
  - Library: `r SL.library`
  - 5-fold cross-validation


## Estimation: G-comp, IPTW, & TMLE

Estimator | ATE (95% CI)
--------------- | ---------------
G-computation | `r round(gComp, 3)`
Stabilized IPTW | `r round(IPTW, 3)`
TMLE | `r round(TMLE$estimate, 3)` (`r round(TMLE$CI[1,1], 3)`, `r round(TMLE$CI[1,2], 3)`)


## Estimation: SuperLearner convex combinations

Algorithm | A Risk | A Coefficient | Y Risk | Y Coefficient
--------- | ---------- | --------- | ---------- | ---------
glm | `r ltmle.SL$fit$g[[2]]$bullied[1,1]` | `r ltmle.SL$fit$g[[2]]$bullied[1,2]` | `r ltmle.SL$fit$Q[[2]]$Y[1.1]` | `r ltmle.SL$fit$Q[[2]]$Y[1,2]`
glm.interaction | `r ltmle.SL$fit$g[[2]]$bullied[2,1]` | `r ltmle.SL$fit$g[[2]]$bullied[2,2]` | `r ltmle.SL$fit$Q[[2]]$Y[2,1]` | `r ltmle.SL$fit$Q[[2]]$Y[2,2]`
glmnet | `r ltmle.SL$fit$g[[2]]$bullied[3,1]` | `r ltmle.SL$fit$g[[2]]$bullied[3,2]` | `r ltmle.SL$fit$Q[[2]]$Y[3,1]` | `r ltmle.SL$fit$Q[[2]]$Y[3,2]`
bayesglm | `r ltmle.SL$fit$g[[2]]$bullied[4,1]` | `r ltmle.SL$fit$g[[2]]$bullied[4,2]` | `r ltmle.SL$fit$Q[[2]]$Y[4,1]` | `r ltmle.SL$fit$Q[[2]]$Y[4,2]`
randomForest | `r ltmle.SL$fit$g[[2]]$bullied[5,1]` | `r ltmle.SL$fit$g[[2]]$bullied[5,2]` | `r ltmle.SL$fit$Q[[2]]$Y[5,1]` | `r ltmle.SL$fit$Q[[2]]$Y[5,2]`
step | `r ltmle.SL$fit$g[[2]]$bullied[6,1]` | `r ltmle.SL$fit$g[[2]]$bullied[6,2]` | `r ltmle.SL$fit$Q[[2]]$Y[6,1]` | `r ltmle.SL$fit$Q[[2]]$Y[6,2]`
mean | `r ltmle.SL$fit$g[[2]]$bullied[7,1]` | `r ltmle.SL$fit$g[[2]]$bullied[7,2]` | `r ltmle.SL$fit$Q[[2]]$Y[7,1]` | `r ltmle.SL$fit$Q[[2]]$Y[7,2]`
loglinear | `r ltmle.SL$fit$g[[2]]$bullied[8,1]` | `r ltmle.SL$fit$g[[2]]$bullied[8,2]` | `r ltmle.SL$fit$Q[[2]]$Y[8,1]` | `r ltmle.SL$fit$Q[[2]]$Y[8,2]`


## Estimation: SuperLearner performance
CV.SuperLearner

Algorithm | Avg Risk | SE 
--------- | ---------- | --------- 
SuperLearner | `r CVtable$Ave[1]` | `r CVtable$se[1]`
Discrete SL | `r CVtable$Ave[2]` | `r CVtable$se[2]`
glm | `r CVtable$Ave[3]` | `r CVtable$se[3]`
glm.interaction | `r CVtable$Ave[4]` | `r CVtable$se[4]`
glmnet | `r CVtable$Ave[5]` | `r CVtable$se[5]`
bayesglm | `r CVtable$Ave[6]` | `r CVtable$se[6]`
randomForest | `r CVtable$Ave[7]` | `r CVtable$se[7]`
step | `r CVtable$Ave[8]` | `r CVtable$se[8]`
mean | `r CVtable$Ave[9]` | `r CVtable$se[9]`
loglinear | `r CVtable$Ave[10]` | `r CVtable$se[10]`


## Results